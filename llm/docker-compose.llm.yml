version: '3.8'

services:
  nllb-service:
    build:
      context: ./nllb
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - HF_HOME=/app/cache
      - TRANSFORMERS_CACHE=/app/cache
    volumes:
      - /home/jamil/models:/app/cache
      - nllb_cache:/app/cache_backup
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 30s
      start_period: 120s
      retries: 3
    restart: unless-stopped

  ollama-service:
    build:
      context: ./ollama
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    volumes:
      - ollama_data:/home/modeluser/.ollama
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8001/health')"]
      interval: 30s
      timeout: 30s
      start_period: 300s
      retries: 5
    restart: unless-stopped

volumes:
  nllb_cache:
    driver: local
  ollama_data:
    driver: local

networks:
  default:
    name: globalnews_network
    external: true